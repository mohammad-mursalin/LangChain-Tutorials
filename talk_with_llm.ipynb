{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cba7393",
   "metadata": {},
   "source": [
    "# Chat Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e6e679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60211898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    " \n",
    "deepseekChatModel = ChatGroq( model = \"llama-3.1-8b-instant\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b59de9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a Python library that allows you to build large language models and connect them to various data sources. To connect to Gemini 2.0 using LangChain, you'll need to follow these steps:\n",
      "\n",
      "1. **Install the required libraries**: Make sure you have LangChain and the Gemini API client installed in your Python environment. You can install them using pip:\n",
      "   ```bash\n",
      "pip install langchain\n",
      "pip install gemini-api\n",
      "```\n",
      "2. **Import the necessary libraries**: In your Python script, import the required libraries:\n",
      "   ```python\n",
      "import langchain\n",
      "from langchain.chains.prompt_tools import PromptTools\n",
      "from gemini.api import PublicClient, PrivateClient\n",
      "```\n",
      "3. **Create a Gemini API client**: You'll need to create instances of the `PublicClient` and `PrivateClient` classes to interact with the Gemini API:\n",
      "   ```python\n",
      "public_client = PublicClient()\n",
      "private_client = PrivateClient('your_api_key', 'your_api_secret')\n",
      "```\n",
      "4. **Define a function to fetch data from Gemini**: Create a function that uses the Gemini API client to fetch the data you need. For example, if you want to fetch the current price of a specific cryptocurrency:\n",
      "   ```python\n",
      "def get_current_price(symbol):\n",
      "    response = public_client.get_ticker(symbol)\n",
      "    current_price = response['last']\n",
      "    return current_price\n",
      "```\n",
      "5. **Integrate the Gemini API with LangChain**: To integrate the Gemini API with LangChain, you'll need to create a custom chain that uses the `get_current_price` function as a step. Here's an example:\n",
      "   ```python\n",
      "chain = langchain.Chain(\n",
      "    input_variables={'symbol': 'BTCUSD'},\n",
      "    steps=[\n",
      "        lambda variables: {'prompt': f'What is the current price of {variables[\"symbol\"]}?'},\n",
      "        lambda variables: {'function': get_current_price, 'input_variables': variables},\n",
      "    ]\n",
      ")\n",
      "```\n",
      "6. **Use the chain to generate a response**: Finally, you can use the chain to generate a response to a user query. For example:\n",
      "   ```python\n",
      "user_input = 'What is the current price of BTCUSD?'\n",
      "response = chain.run(user_input)\n",
      "print(response)\n",
      "```\n",
      "Note that this is just an example and you'll need to adapt it to your specific use case. Additionally, be sure to handle any errors that may occur when interacting with the Gemini API.\n",
      "\n",
      "Here is the full code:\n",
      "```python\n",
      "import langchain\n",
      "from langchain.chains.prompt_tools import PromptTools\n",
      "from gemini.api import PublicClient, PrivateClient\n",
      "\n",
      "public_client = PublicClient()\n",
      "private_client = PrivateClient('your_api_key', 'your_api_secret')\n",
      "\n",
      "def get_current_price(symbol):\n",
      "    response = public_client.get_ticker(symbol)\n",
      "    current_price = response['last']\n",
      "    return current_price\n",
      "\n",
      "# Integrate the Gemini API with LangChain\n",
      "chain = langchain.Chain(\n",
      "    input_variables={'symbol': 'BTCUSD'},\n",
      "    steps=[\n",
      "        lambda variables: {'prompt': f'What is the current price of {variables[\"symbol\"]}?'},\n",
      "        lambda variables: {'function': get_current_price, 'input_variables': variables},\n",
      "    ]\n",
      ")\n",
      "\n",
      "# Use the chain to generate a response\n",
      "user_input = 'What is the current price of BTCUSD?'\n",
      "response = chain.run(user_input)\n",
      "print(response)\n",
      "```\n",
      "Make sure to replace `'your_api_key'` and `'your_api_secret'` with your actual Gemini API key and secret.\n"
     ]
    }
   ],
   "source": [
    "message = [\n",
    "    (\"system\", \"you are a programmer\"),\n",
    "    (\"human\", \"how can i connect to gemini 2.0 flash using langchain\")\n",
    "]\n",
    "\n",
    "response = deepseekChatModel.invoke(message)\n",
    "\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
