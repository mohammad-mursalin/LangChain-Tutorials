{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d733e1a-fff5-4739-b702-cc4af0a69d41",
   "metadata": {},
   "source": [
    "# How to build a simple Chatbot with stored memory using LangChain\n",
    "* Simple Chatbot LLM App.\n",
    "    * Will be able to have a conversation.\n",
    "    * Will remember previous interactions: will have memory.\n",
    "    * Will be able to store memory in a json file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c88f7",
   "metadata": {},
   "source": [
    "A chatbot app is a software application designed to simulate conversation with human users. It uses artificial intelligence (AI) to understand what someone is saying and to respond with appropriate answers. These apps can be used for various purposes like customer support, providing information, or entertainment. Essentially, it's like texting with a program that can answer questions and help with tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0399355-dece-4701-9bf4-4c204fe74929",
   "metadata": {},
   "source": [
    "## Concepts included\n",
    "* Chat Model vs. LLM Model:\n",
    "    *  Chat Model is based around messages.\n",
    "    *  LLM Model is based around raw text.\n",
    "* Chat History: allows Chat Model to remember previous interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7584e1f0-5e9e-4e45-850c-c606234b6ee2",
   "metadata": {},
   "source": [
    "## Trick to avoid the nasty deprecation warnings from LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b4224a-d719-46fd-b261-dd913b17ec86",
   "metadata": {},
   "source": [
    "In this exercise we will use the LangChain legacy chain LLMChain. It works well, but LangChain displays a nasty deprecation warning. To avoid it, we will enter the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddbcf93-0b58-4506-af83-2fa2203c711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from langchain._api import LangChainDeprecationWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8626f160-fcd3-41ca-a5ab-3e98f11595a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "992ec4a9-aa01-4e44-aeb9-b9a1f3aa9e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01d18b-f9f0-427b-a9dc-3d1885160578",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceed6d60-5cbd-43e4-9a69-ed71d82a2a9b",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed746499-d1b8-41e5-b131-270cf5fa229b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2af3ef-c2c7-445f-92bd-a29c68abce25",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659bdc4c-484d-4ec0-89b6-5f1e979610ce",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3fa7337f-3d60-4ede-bdf8-aa7a5cffec43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce3551e-95ca-41a1-8810-89c495bf93ab",
   "metadata": {},
   "source": [
    "* For this project, we will use Groqs's llama-3.1-8b-instant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9afcbc7d-a816-41e3-925f-850883f5770d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "chatbot = ChatGroq(model = \"llama-3.1-8b-instant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a1d409-7f2f-40a4-90c5-ad77dad3edce",
   "metadata": {},
   "source": [
    "* Human Message: the user input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5dc0613-fb6d-4c82-a614-9e7307714303",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "messagesToTheChatbot = [\n",
    "    HumanMessage(content=\"My favorite color is blue.\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b36ec-341a-47bc-af32-30cfb939810d",
   "metadata": {},
   "source": [
    "#### Call the ChatModel (the LLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db815e32-8e60-46b3-8cce-fbf40e378397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Blue is a beautiful and calming color. It can evoke feelings of serenity, trust, and stability. Many people find blue to be a soothing and relaxing color, which is why it's often associated with the sky and the ocean.\\n\\nThere are also many different shades of blue, each with its own unique character. Do you have a specific shade of blue that you like best, such as navy, royal blue, or sky blue?\", response_metadata={'token_usage': {'completion_tokens': 88, 'prompt_tokens': 41, 'total_tokens': 129, 'completion_time': 0.114893197, 'prompt_time': 0.002422617, 'queue_time': 0.054741163, 'total_time': 0.117315814}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'finish_reason': 'stop', 'logprobs': None}, id='run-096239d4-3a86-4d22-b59e-74aef8b603b7-0', usage_metadata={'input_tokens': 41, 'output_tokens': 88, 'total_tokens': 129})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke(messagesToTheChatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9913fc8c-254f-410d-aa8f-35eb0898855e",
   "metadata": {},
   "source": [
    "#### Track the operation in LangSmith\n",
    "* [Open LangSmith here](smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e62b67b-9798-4705-8b8a-dbfdf8c93ed8",
   "metadata": {},
   "source": [
    "## Check if the Chatbot remembers your favorite color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ead4ee-bda3-4c52-9bdb-7bf234733055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm not aware of any information about your favorite color. I'm a large language model, I don't have personal knowledge about individuals, and our conversation just started. If you'd like to share your favorite color, I'd be happy to chat with you about it!\", response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 41, 'total_tokens': 97, 'completion_time': 0.063440976, 'prompt_time': 0.003699548, 'queue_time': 0.050189662, 'total_time': 0.067140524}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'finish_reason': 'stop', 'logprobs': None}, id='run-45ef18db-85b5-4394-a207-c3e7fa3f43fb-0', usage_metadata={'input_tokens': 41, 'output_tokens': 56, 'total_tokens': 97})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatbot.invoke([\n",
    "    HumanMessage(content=\"What is my favorite color?\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec947e-b9b7-43e3-ac67-60027e049f3c",
   "metadata": {},
   "source": [
    "* As you can see, our Chatbot cannot remember our previous interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df0143e-8bc8-45ad-ac6f-05aaf659c683",
   "metadata": {},
   "source": [
    "## Let's add memory to our Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6062df1-33ce-436e-b5b2-cea78ae7b860",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23533a37-6060-4d32-9b0c-36a9ea57a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "735752cc-ecb5-4942-9ed0-b3213f5768c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts import HumanMessagePromptTemplate\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.memory import FileChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542bbf66-bc77-4488-8487-b55cdb8bc8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    chat_memory=FileChatMessageHistory(\"messages.json\"),\n",
    "    memory_key=\"messages\",\n",
    "    return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27e8431b-5290-4f7f-9566-a90deb060bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate(\n",
    "    input_variables=[\"content\", \"messages\"],\n",
    "    messages=[\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{content}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72392539-0f20-456b-b32d-d367b48245f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(\n",
    "    llm=chatbot,\n",
    "    prompt=prompt,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57e40af4-1539-497d-afbf-ed38fed90838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'hello!',\n",
       " 'messages': [],\n",
       " 'text': 'Hello! How can I assist you today?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hello!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b79cc08-49dd-4746-ab68-9d8ec992abb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'my name is mursalin',\n",
       " 'messages': [HumanMessage(content='hello!'),\n",
       "  AIMessage(content='Hello! How can I assist you today?')],\n",
       " 'text': 'Nice to meet you, Mursalin. Is there something I can help you with or would you like to chat?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"my name is mursalin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96e69c4f-b5ed-4c68-9a2a-67a19867f8bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'content': 'what is my name?',\n",
       " 'messages': [HumanMessage(content='hello!'),\n",
       "  AIMessage(content='Hello! How can I assist you today?'),\n",
       "  HumanMessage(content='my name is mursalin'),\n",
       "  AIMessage(content='Nice to meet you, Mursalin. Is there something I can help you with or would you like to chat?')],\n",
       " 'text': 'Your name is Mursalin.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44245124-ef39-4269-a099-21c9c31c08bb",
   "metadata": {},
   "source": [
    "* Check the file messages.json in the root directory.\n",
    "* This is just a simple example, in the real world you probably will not save your memory in a json file. \n",
    "* And remember: the context window is limited and it affects to the cost of using  Chat Models API."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
